{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5 base Fine-Tuned on custom Amazon Dataset - TRAINING FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:25:20.860164Z",
     "iopub.status.busy": "2023-07-31T04:25:20.859738Z",
     "iopub.status.idle": "2023-07-31T04:25:27.246136Z",
     "shell.execute_reply": "2023-07-31T04:25:27.245140Z",
     "shell.execute_reply.started": "2023-07-31T04:25:20.860131Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login() # add your api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:25:27.541164Z",
     "iopub.status.busy": "2023-07-31T04:25:27.540877Z",
     "iopub.status.idle": "2023-07-31T04:25:42.131688Z",
     "shell.execute_reply": "2023-07-31T04:25:42.130716Z",
     "shell.execute_reply.started": "2023-07-31T04:25:27.541140Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import collections\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:25:42.134400Z",
     "iopub.status.busy": "2023-07-31T04:25:42.133845Z",
     "iopub.status.idle": "2023-07-31T04:25:42.963968Z",
     "shell.execute_reply": "2023-07-31T04:25:42.962982Z",
     "shell.execute_reply.started": "2023-07-31T04:25:42.134372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10375"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_meta = \"/kaggle/input/cell-phones-final/Cell_Phones_and_Accessories_final.json\"\n",
    "\n",
    "with open(path_meta,'r') as file:\n",
    "    data = json.load(file)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:25:45.945157Z",
     "iopub.status.busy": "2023-07-31T04:25:45.944778Z",
     "iopub.status.idle": "2023-07-31T04:25:45.955657Z",
     "shell.execute_reply": "2023-07-31T04:25:45.954600Z",
     "shell.execute_reply.started": "2023-07-31T04:25:45.945125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'B0015X7RSO',\n",
       " 'title': 'HTC Sprint Touch P3450 Smartphone Black Swivel Belt Clip Holster',\n",
       " 'context': 'It is a Generic product. Don apos t ever leave your phone behind again. By attaching our holster you can clip your phone onto your belt or just anywhere and feel free while your phone is secured. Brand new non OEM Custom made to fit your HTC Touch perfectly. Includes a swivel belt clip. Categories of product are Cell Phones Accessories Cases Holsters Sleeves',\n",
       " 'qas': [{'answer': {'answer_start': 8, 'text': 'Generic'},\n",
       "   'question': 'What type of product is it?'},\n",
       "  {'answer': {'answer_start': 29, 'text': 'apos'},\n",
       "   'question': 'What is the name of the name of the person who is responsible for leaving a phone behind?'},\n",
       "  {'answer': {'answer_start': 89, 'text': 'holster'},\n",
       "   'question': 'What is the name of the accessory that allows you to clip your phone onto your belt?'},\n",
       "  {'answer': {'answer_start': 210, 'text': 'OEM'},\n",
       "   'question': 'What is the name of the company that makes the HTC Touch?'},\n",
       "  {'answer': {'answer_start': 270, 'text': 'swivel'},\n",
       "   'question': 'What type of belt clip is included?'},\n",
       "  {'answer': {'answer_start': 314,\n",
       "    'text': 'Cell Phones Accessories Cases Holsters Sleeves'},\n",
       "   'question': 'What are the categories of product?'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:25:48.490970Z",
     "iopub.status.busy": "2023-07-31T04:25:48.490270Z",
     "iopub.status.idle": "2023-07-31T04:25:49.234192Z",
     "shell.execute_reply": "2023-07-31T04:25:49.233133Z",
     "shell.execute_reply.started": "2023-07-31T04:25:48.490936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e76c44f0d942f8b95af09f90a493bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f601a560a3a409bae2f065b87f30cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49935f27224e446c9fb9c50a1f302c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer= AutoTokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:25:49.237710Z",
     "iopub.status.busy": "2023-07-31T04:25:49.236059Z",
     "iopub.status.idle": "2023-07-31T04:25:49.257859Z",
     "shell.execute_reply": "2023-07-31T04:25:49.256467Z",
     "shell.execute_reply.started": "2023-07-31T04:25:49.237670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 980, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_short = data[:5000]\n",
    "random.shuffle(data)\n",
    "train_data = data_short[:int(0.8*len(data_short))]\n",
    "val_data = data_short[int(0.8*len(data_short)):int(0.996*len(data_short))]\n",
    "test_data = data_short[int(0.996*len(data_short)):]\n",
    "len(train_data),len(val_data),len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:25:52.352037Z",
     "iopub.status.busy": "2023-07-31T04:25:52.351345Z",
     "iopub.status.idle": "2023-07-31T04:25:52.362734Z",
     "shell.execute_reply": "2023-07-31T04:25:52.361703Z",
     "shell.execute_reply.started": "2023-07-31T04:25:52.352003Z"
    }
   },
   "outputs": [],
   "source": [
    "# storing test data seprately\n",
    "with open(\"/kaggle/working/Cell_Phones_and_Accessories_testflie.json\",'w') as file:\n",
    "    json.dump(test_data,file,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokeinzing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:25:59.393865Z",
     "iopub.status.busy": "2023-07-31T04:25:59.393502Z",
     "iopub.status.idle": "2023-07-31T04:25:59.439476Z",
     "shell.execute_reply": "2023-07-31T04:25:59.438453Z",
     "shell.execute_reply.started": "2023-07-31T04:25:59.393835Z"
    }
   },
   "outputs": [],
   "source": [
    "# function extracts answers, questions, and contexts from the dataset\n",
    "def data_prep(data):\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for prod in data:\n",
    "        context = prod['context']\n",
    "        for i in range(len(prod['qas'])):\n",
    "            question = prod['qas'][i]['question']\n",
    "            answer = prod['qas'][i]['answer']['text']\n",
    "            contexts.append(context)\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "    return contexts,questions,answers\n",
    "\n",
    "train_contexts,train_questions,train_answers = data_prep(train_data)\n",
    "val_contexts,val_questions,val_answers = data_prep(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:25:59.703739Z",
     "iopub.status.busy": "2023-07-31T04:25:59.703353Z",
     "iopub.status.idle": "2023-07-31T04:26:31.313516Z",
     "shell.execute_reply": "2023-07-31T04:26:31.312463Z",
     "shell.execute_reply.started": "2023-07-31T04:25:59.703708Z"
    }
   },
   "outputs": [],
   "source": [
    "# function tokenizes the questions and contexts together and labels seprately\n",
    "def encode_prep(questions,contexts,answers):\n",
    "    encode_qa = tokenizer(questions,contexts,truncation=True,padding=\"max_length\",max_length = 512,pad_to_max_length=True,\n",
    "                          add_special_tokens=True)\n",
    "    encode_ans = tokenizer(answers,truncation=True,padding=\"max_length\",max_length = 25,pad_to_max_length=True,\n",
    "                          add_special_tokens=True)\n",
    "    labels = encode_ans[\"input_ids\"]\n",
    "    encode_qa.update({'labels':labels,\"decoder_attention_mask\":encode_ans[\"attention_mask\"]})\n",
    "\n",
    "    return encode_qa\n",
    "\n",
    "train_embedding = encode_prep(train_questions,train_contexts,train_answers)\n",
    "val_embedding = encode_prep(val_questions,val_contexts,val_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:26:31.315714Z",
     "iopub.status.busy": "2023-07-31T04:26:31.315343Z",
     "iopub.status.idle": "2023-07-31T04:26:31.322329Z",
     "shell.execute_reply": "2023-07-31T04:26:31.320529Z",
     "shell.execute_reply.started": "2023-07-31T04:26:31.315681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33252 8199\n"
     ]
    }
   ],
   "source": [
    "print(len(train_embedding['input_ids']),len(val_embedding['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 base for Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:27:34.068350Z",
     "iopub.status.busy": "2023-07-31T04:27:34.067346Z",
     "iopub.status.idle": "2023-07-31T04:27:34.076549Z",
     "shell.execute_reply": "2023-07-31T04:27:34.075210Z",
     "shell.execute_reply.started": "2023-07-31T04:27:34.068312Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating instance of dataset to feed the model\n",
    "class prodDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = prodDataset(train_embedding)\n",
    "val_dataset = prodDataset(val_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:27:34.461169Z",
     "iopub.status.busy": "2023-07-31T04:27:34.458012Z",
     "iopub.status.idle": "2023-07-31T04:27:35.411662Z",
     "shell.execute_reply": "2023-07-31T04:27:35.410498Z",
     "shell.execute_reply.started": "2023-07-31T04:27:34.461131Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq,Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:27:35.418292Z",
     "iopub.status.busy": "2023-07-31T04:27:35.417194Z",
     "iopub.status.idle": "2023-07-31T04:27:35.533490Z",
     "shell.execute_reply": "2023-07-31T04:27:35.532445Z",
     "shell.execute_reply.started": "2023-07-31T04:27:35.418248Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "model_name = \"t5-base-qa\"\n",
    "model_dir = \"/kaggle/working/model\"\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    model_dir,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy='epoch',\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:27:36.006587Z",
     "iopub.status.busy": "2023-07-31T04:27:36.006177Z",
     "iopub.status.idle": "2023-07-31T04:27:36.011463Z",
     "shell.execute_reply": "2023-07-31T04:27:36.010397Z",
     "shell.execute_reply.started": "2023-07-31T04:27:36.006553Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:27:39.023119Z",
     "iopub.status.busy": "2023-07-31T04:27:39.022746Z",
     "iopub.status.idle": "2023-07-31T04:27:54.673233Z",
     "shell.execute_reply": "2023-07-31T04:27:54.672220Z",
     "shell.execute_reply.started": "2023-07-31T04:27:39.023072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aba8e8917b1458bb7d93be34144715b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ea9c68f3524ecfbbad08c80ea2d9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T04:27:56.181473Z",
     "iopub.status.busy": "2023-07-31T04:27:56.180594Z",
     "iopub.status.idle": "2023-07-31T06:50:18.256395Z",
     "shell.execute_reply": "2023-07-31T06:50:18.255338Z",
     "shell.execute_reply.started": "2023-07-31T04:27:56.181427Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvinayakpanchal99\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230731_042756-2yk4zw6o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vinayakpanchal99/huggingface/runs/2yk4zw6o' target=\"_blank\">vivid-mountain-18</a></strong> to <a href='https://wandb.ai/vinayakpanchal99/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vinayakpanchal99/huggingface' target=\"_blank\">https://wandb.ai/vinayakpanchal99/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vinayakpanchal99/huggingface/runs/2yk4zw6o' target=\"_blank\">https://wandb.ai/vinayakpanchal99/huggingface/runs/2yk4zw6o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6237' max='6237' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6237/6237 2:21:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.039269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.033455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.033556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6237, training_loss=0.04874797660187878, metrics={'train_runtime': 8541.3828, 'train_samples_per_second': 11.679, 'train_steps_per_second': 0.73, 'total_flos': 6.074720333070336e+16, 'train_loss': 0.04874797660187878, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T06:58:04.449844Z",
     "iopub.status.busy": "2023-07-31T06:58:04.449466Z",
     "iopub.status.idle": "2023-07-31T06:58:06.152285Z",
     "shell.execute_reply": "2023-07-31T06:58:06.151078Z",
     "shell.execute_reply.started": "2023-07-31T06:58:04.449811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/model/t5base/tokenizer_config.json',\n",
       " '/kaggle/working/model/t5base/special_tokens_map.json',\n",
       " '/kaggle/working/model/t5base/spiece.model',\n",
       " '/kaggle/working/model/t5base/added_tokens.json',\n",
       " '/kaggle/working/model/t5base/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"/kaggle/working/model/t5base\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working/model/t5base\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
